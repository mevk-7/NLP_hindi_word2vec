{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import glob\n",
    "import logging\n",
    "import multiprocessing\n",
    "import os\n",
    "import pprint\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import gensim.models.word2vec as w2v\n",
    "import gensim\n",
    "import sklearn.manifold\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found books:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['final.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_filenames = sorted(glob.glob(\"final.txt\"))\n",
    "print(\"Found books:\")\n",
    "book_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 'final.txt'...\n",
      "Corpus is now 14981857 characters long\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corpus_raw = u\"\"\n",
    "for book_filename in book_filenames:\n",
    "    print(\"Reading '{0}'...\".format(book_filename))\n",
    "    with codecs.open(book_filename, \"r\", \"utf-8\") as book_file:\n",
    "        corpus_raw += book_file.read()\n",
    "    print(\"Corpus is now {0} characters long\".format(len(corpus_raw)))\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(sentences):\n",
    "    corpus = list(sentences.split('.'))\n",
    "    for i in corpus:\n",
    "        i.replace('\\n',' ')\n",
    "    return corpus\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' इस विधा में व्यक्त हुई कविता\\nगेय होती है', ' इसलिए गीत की पहचान उसकी गेयता में निहित होती है', ' इसलिए गीत तभी गीत\\nहै जब वह गेय हो', ' इसलिए जो कविता गेय नहीं है वह गीत नहीं है']\n"
     ]
    }
   ],
   "source": [
    "raw_sentences = tokenize(corpus_raw)\n",
    "print(raw_sentences[1:5])\n",
    "def sentence_to_wordlist(raw):\n",
    "    clean = re.compile(\"[^\\p{Zs}\\p{P}]\")\n",
    "    words = clean.sub(\" \",raw)\n",
    "    #words = re.sub(\"[^\\p{Zs}\\p{P}]\",\" \",raw)\n",
    "    words = words.split()\n",
    "    return words\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for raw_sentence in raw_sentences:\n",
    "    if len(raw_sentence) > 0:\n",
    "        #sentences.append(sentence_to_wordlist(raw_sentence))\n",
    "        sentences.append(raw_sentence.split())\n",
    "#print(raw_sentences[5])\n",
    "#print(sentence_to_wordlist(raw_sentences[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-02-16 19:30:15,088 : INFO : collecting all words and their counts\n",
      "2018-02-16 19:30:15,092 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-02-16 19:30:15,135 : INFO : PROGRESS: at sentence #10000, processed 168256 words, keeping 23234 word types\n",
      "2018-02-16 19:30:15,187 : INFO : PROGRESS: at sentence #20000, processed 335983 words, keeping 38498 word types\n",
      "2018-02-16 19:30:15,218 : INFO : PROGRESS: at sentence #30000, processed 497512 words, keeping 51255 word types\n",
      "2018-02-16 19:30:15,268 : INFO : PROGRESS: at sentence #40000, processed 649825 words, keeping 61830 word types\n",
      "2018-02-16 19:30:15,310 : INFO : PROGRESS: at sentence #50000, processed 803572 words, keeping 72331 word types\n",
      "2018-02-16 19:30:15,349 : INFO : PROGRESS: at sentence #60000, processed 969289 words, keeping 84228 word types\n",
      "2018-02-16 19:30:15,393 : INFO : PROGRESS: at sentence #70000, processed 1129603 words, keeping 94058 word types\n",
      "2018-02-16 19:30:15,447 : INFO : PROGRESS: at sentence #80000, processed 1291572 words, keeping 103287 word types\n",
      "2018-02-16 19:30:15,481 : INFO : PROGRESS: at sentence #90000, processed 1446616 words, keeping 113510 word types\n",
      "2018-02-16 19:30:15,533 : INFO : PROGRESS: at sentence #100000, processed 1611833 words, keeping 122570 word types\n",
      "2018-02-16 19:30:15,578 : INFO : PROGRESS: at sentence #110000, processed 1773754 words, keeping 133099 word types\n",
      "2018-02-16 19:30:15,610 : INFO : PROGRESS: at sentence #120000, processed 1924913 words, keeping 140828 word types\n",
      "2018-02-16 19:30:15,668 : INFO : PROGRESS: at sentence #130000, processed 2094079 words, keeping 148239 word types\n",
      "2018-02-16 19:30:15,700 : INFO : PROGRESS: at sentence #140000, processed 2240742 words, keeping 155448 word types\n",
      "2018-02-16 19:30:15,752 : INFO : PROGRESS: at sentence #150000, processed 2403525 words, keeping 163267 word types\n",
      "2018-02-16 19:30:15,787 : INFO : PROGRESS: at sentence #160000, processed 2571240 words, keeping 171347 word types\n",
      "2018-02-16 19:30:15,836 : INFO : PROGRESS: at sentence #170000, processed 2732651 words, keeping 179628 word types\n",
      "2018-02-16 19:30:15,878 : INFO : collected 184950 word types from a corpus of 2859115 raw words and 177647 sentences\n",
      "2018-02-16 19:30:15,879 : INFO : Loading a fresh vocabulary\n",
      "2018-02-16 19:30:15,989 : INFO : min_count=5 retains 27700 unique words (14% of original 184950, drops 157250)\n",
      "2018-02-16 19:30:15,990 : INFO : min_count=5 leaves 2639954 word corpus (92% of original 2859115, drops 219161)\n",
      "2018-02-16 19:30:16,110 : INFO : deleting the raw counts dictionary of 184950 items\n",
      "2018-02-16 19:30:16,115 : INFO : sample=0.001 downsamples 34 most-common words\n",
      "2018-02-16 19:30:16,116 : INFO : downsampling leaves estimated 2100672 word corpus (79.6% of prior 2639954)\n",
      "2018-02-16 19:30:16,242 : INFO : estimated required memory for 27700 words and 100 dimensions: 36010000 bytes\n",
      "2018-02-16 19:30:16,243 : INFO : resetting layer weights\n",
      "2018-02-16 19:30:16,579 : INFO : training model with 3 workers on 27700 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-02-16 19:30:17,674 : INFO : EPOCH 1 - PROGRESS: at 24.73% examples, 521557 words/s, in_qsize 5, out_qsize 0\n",
      "2018-02-16 19:30:18,685 : INFO : EPOCH 1 - PROGRESS: at 69.73% examples, 724860 words/s, in_qsize 5, out_qsize 0\n",
      "2018-02-16 19:30:19,369 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-02-16 19:30:19,375 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-02-16 19:30:19,380 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-02-16 19:30:19,380 : INFO : EPOCH - 1 : training on 2859115 raw words (2101053 effective words) took 2.7s, 775376 effective words/s\n",
      "2018-02-16 19:30:20,390 : INFO : EPOCH 2 - PROGRESS: at 43.92% examples, 924140 words/s, in_qsize 5, out_qsize 0\n",
      "2018-02-16 19:30:21,402 : INFO : EPOCH 2 - PROGRESS: at 88.97% examples, 925570 words/s, in_qsize 5, out_qsize 0\n",
      "2018-02-16 19:30:21,637 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-02-16 19:30:21,639 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-02-16 19:30:21,648 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-02-16 19:30:21,649 : INFO : EPOCH - 2 : training on 2859115 raw words (2100644 effective words) took 2.3s, 928840 effective words/s\n",
      "2018-02-16 19:30:22,666 : INFO : EPOCH 3 - PROGRESS: at 43.62% examples, 915462 words/s, in_qsize 6, out_qsize 0\n",
      "2018-02-16 19:30:23,685 : INFO : EPOCH 3 - PROGRESS: at 79.63% examples, 823879 words/s, in_qsize 4, out_qsize 1\n",
      "2018-02-16 19:30:24,249 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-02-16 19:30:24,250 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-02-16 19:30:24,253 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-02-16 19:30:24,254 : INFO : EPOCH - 3 : training on 2859115 raw words (2100560 effective words) took 2.6s, 810614 effective words/s\n",
      "2018-02-16 19:30:25,282 : INFO : EPOCH 4 - PROGRESS: at 43.28% examples, 892792 words/s, in_qsize 5, out_qsize 0\n",
      "2018-02-16 19:30:26,285 : INFO : EPOCH 4 - PROGRESS: at 78.69% examples, 812105 words/s, in_qsize 5, out_qsize 0\n",
      "2018-02-16 19:30:26,759 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-02-16 19:30:26,765 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-02-16 19:30:26,768 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-02-16 19:30:26,769 : INFO : EPOCH - 4 : training on 2859115 raw words (2099790 effective words) took 2.5s, 837429 effective words/s\n",
      "2018-02-16 19:30:27,798 : INFO : EPOCH 5 - PROGRESS: at 44.59% examples, 927996 words/s, in_qsize 6, out_qsize 1\n",
      "2018-02-16 19:30:28,799 : INFO : EPOCH 5 - PROGRESS: at 89.33% examples, 928816 words/s, in_qsize 5, out_qsize 0\n",
      "2018-02-16 19:30:29,032 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-02-16 19:30:29,043 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-02-16 19:30:29,048 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-02-16 19:30:29,049 : INFO : EPOCH - 5 : training on 2859115 raw words (2101084 effective words) took 2.3s, 927211 effective words/s\n",
      "2018-02-16 19:30:29,053 : INFO : training on a 14295575 raw words (10503131 effective words) took 12.5s, 842055 effective words/s\n",
      "2018-02-16 19:30:29,160 : INFO : saving Word2Vec object under hindi_model, separately None\n",
      "2018-02-16 19:30:29,163 : INFO : not storing attribute vectors_norm\n",
      "2018-02-16 19:30:29,166 : INFO : not storing attribute cum_table\n",
      "2018-02-16 19:30:29,541 : INFO : saved hindi_model\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec(sentences, min_count=5)\n",
    "model.save(\"hindi_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model = w2v.load('hindi_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec vocabulary length: 27700\n"
     ]
    }
   ],
   "source": [
    "print(\"Word2Vec vocabulary length:\", len(model.wv.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntsne = sklearn.manifold.TSNE(n_components=2, random_state=0)\\nall_word_vectors_matrix = model.syn0\\nall_word_vectors_matrix_2d = tsne.fit_transform(all_word_vectors_matrix)\\n\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualize data\n",
    "'''\n",
    "tsne = sklearn.manifold.TSNE(n_components=2, random_state=0)\n",
    "all_word_vectors_matrix = model.syn0\n",
    "all_word_vectors_matrix_2d = tsne.fit_transform(all_word_vectors_matrix)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vikrant/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "2018-02-16 19:29:45,127 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('वाक्य', 0.8962609767913818),\n",
       " ('कलाकार', 0.8897086381912231),\n",
       " ('अक्षर', 0.8890184164047241),\n",
       " ('देवता', 0.8859585523605347),\n",
       " ('परिवेश', 0.8826315402984619),\n",
       " ('प्राणी', 0.881984293460846),\n",
       " ('जीव', 0.8801188468933105),\n",
       " ('पाठक', 0.8779338598251343),\n",
       " ('कवि', 0.876211941242218),\n",
       " ('राग', 0.8735357522964478)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"गीत\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vikrant/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "2018-02-16 19:31:37,585 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('देवियों', 0.853697657585144),\n",
       " ('कृतियों', 0.842225968837738),\n",
       " ('देवी-देवताओं', 0.8305516242980957),\n",
       " ('प्रथाओं', 0.8270368576049805),\n",
       " ('शिक्षा-शास्त्रियों', 0.8257018327713013),\n",
       " ('कवियों', 0.8217662572860718),\n",
       " ('गाथा', 0.8204354047775269),\n",
       " ('परम्पराओं', 0.8169021606445312),\n",
       " ('मानसिकता', 0.8167558908462524),\n",
       " ('विद्या', 0.81500244140625)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('कविताओं')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
